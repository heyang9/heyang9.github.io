<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>呜呜部落格(•̀ᴗ•́)و ̑̑</title>

  
  <meta name="author" content="Yang He">
  

  

  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="呜呜部落格(•̀ᴗ•́)و ̑̑"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="呜呜部落格(•̀ᴗ•́)و ̑̑" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">呜呜部落格(•̀ᴗ•́)و ̑̑</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    
  <article>

  
    
    <h3 class="article-title"><a href="/2017/05/06/写写常见的几种最优化方法/"><span>梯度下降法和牛顿法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/05/06/写写常见的几种最优化方法/" rel="bookmark">
        <time class="entry-date published" datetime="2017-05-06T08:35:00.000Z">
          2017-05-06
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="写写常见的几种最优化方法"><a href="#写写常见的几种最优化方法" class="headerlink" title="写写常见的几种最优化方法"></a>写写常见的几种最优化方法</h2><p>首先肯定是要说泰勒公式的了。。</p>
<p>泰勒公式是一个用函数在某点的信息描述其<em>附近</em>取值的公式。</p>
<p><strong>局部有效性</strong></p>
<p>它的基本形式是：<img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5hmziysij31kw089tan.jpg" alt=""></p>
<p>这是后续优化方法的迭代基础</p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>在机器学习任务中，需要最小化损失函数L（theta），其中theta是要求解的模型参数。梯度下降法常用来求解这种无约束最优化问题，它是一种迭代方法:选取初值，不断迭代，更新theta的值，进行损失函数的极小化。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/006cxA6Hgy1fp5ht3pqwqj31kw0n8n2l.jpg" alt=""></p>
<p>这个图大概能表示梯度下降搜索迭代的概念</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Gradient_descent.png/350px-Gradient_descent.png" alt=""></p>
<p>同时还有共轭梯度下降，次梯度下降等。　共轭梯度法是介于最速下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。 在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。</p>
<p>还有两个概念：批量梯度下降法（Batch Gradient Descent，BGD），它得到的是一个全局最优解，但是每迭代一步，都要用到训练集所有的数据，如果m很大，那么可想而知这种方法的迭代速度会相当的慢。所以，这就引入了另外一种方法——随机梯度下降。随机梯度下降（Stochastic Gradient Descent，SGD）：随机梯度下降是通过每个样本来迭代更新一次，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将theta迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p>
<p>随机梯度下降每次迭代只使用一个样本，迭代一次计算量为n2，当样本个数m很大的时候，随机梯度下降迭代一次的速度要远高于批量梯度下降方法。两者的关系可以这样理解：随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量。</p>
<p>对批量梯度下降法和随机梯度下降法的总结：</p>
<p>   批量梯度下降—最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。</p>
<p>随机梯度下降—最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。</p>
<p>所以引入了mini-batch 梯度下降的概念，很棒了。</p>
<h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p>牛顿法和梯度下降法最直观的差别就是，前者进行了二阶的泰勒展开：</p>
<p><img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5hxpzbrbj31kw0xnwn8.jpg" alt=""><br>一个动图<br><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif" alt=""></p>
<p>从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<p>但是！牛顿法每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</p>
<p>所以就有了拟牛顿法</p>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p>拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p>
<p>这个又有很多内容了，DFP，BFGS啥的，在python里用起来很方便，但是最好还是要弄懂原理的，感觉心里会更清晰一点呢✌🏻</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/03/21/机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系/"><span>Bias(偏差)，Error(误差)，和Variance(方差)</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/03/21/机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系/" rel="bookmark">
        <time class="entry-date published" datetime="2017-03-21T02:31:23.000Z">
          2017-03-21
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="机器学习中的Bias-偏差-，Error-误差-，和Variance-方差-的区别和联系"><a href="#机器学习中的Bias-偏差-，Error-误差-，和Variance-方差-的区别和联系" class="headerlink" title="机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系"></a>机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系</h2><p>这个比较基础的概念我觉得是很好理解的👌🏻</p>
<p>看图</p>
<p><img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5gbz8cmfj30k00tw0u5.jpg" alt=""></p>
<p>这个图基本上就能看懂他们的区别联系了：bias描述的是模型输出的<strong>预测结果的期望</strong>与真实结果的差距，如果要减小bias就需要增加模型复杂度，但是容易出现过拟合的情况，如右上图，会很分散（容易收到样本数据影响，稍微的扰动会带来很大影响）</p>
<p>variance和bias不同的是，它不是对样本拟合程度的反应，它表现的是模型在测试集上的表现，降低方差需要减小模型复杂度，但是会容易欠拟合，带来的结果是high bias。</p>
<p>一句话：</p>
<p>Bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异；<br>Variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。</p>
<p>所以bias和variance的选择是一个tradeoff。</p>
<p>噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p>Error = Bias^2 + Variance + Noise</p>
<p>不列出具体推导了，周志华老师的机器学习中写的很明白</p>
<h3 id="怎么避免过拟合和欠拟合"><a href="#怎么避免过拟合和欠拟合" class="headerlink" title="怎么避免过拟合和欠拟合"></a>怎么避免过拟合和欠拟合</h3><pre><code>避免欠拟合：

寻找更好的特征-----具有代表性的

用更多的特征-----增大输入向量的维度


避免过拟合：
增大数据集合-----使用更多的数据，噪声点比重减少

减少数据特征-----减小数据维度，高维空间密度小

正则化方法-----即在对模型的目标函数（objective function）或代价函数（cost function）加上正则项

交叉验证方法
</code></pre><h3 id="什么是交叉验证"><a href="#什么是交叉验证" class="headerlink" title="什么是交叉验证"></a>什么是交叉验证</h3><p>Cross-validation 是为了有效的估测 generalization error(泛化误差) 所设计的实验方法</p>
<p>将原始数据分成K组(一般是均分),将每个子集数据分别做一次验证集,其余的K-1组子集数据作为训练集,这样会得到K个模型,用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标.K一般大于等于2,实际操作时一般从3开始取,只有在原始数据集合数据量小的时候才会尝试取2. 而K-CV 的实验共需要建立 k 个models，并计算 k 次 test sets 的平均辨识率。在实作上，k 要够大才能使各回合中的 训练样本数够多，一般而言 k=10 (作为一个经验参数)算是相当足够了。</p>
<p>为什么要交叉验证呢：k-fold交叉验证常用来确定不同类型的模型（线性、指数等）哪一种更好，为了减少数据划分对模型评价的影响，最终选出来的模型类型（线性、指数等）是k次建模的误差平均值最小的模型。当k较大时，经过更多次数的平均可以学习得到更符合真实数据分布的模型，Bias就小了，但是这样一来模型就更加拟合训练数据集，再去测试集上预测的时候预测误差的期望值就变大了，从而Variance就大了；反之，k较小时模型不会过度拟合训练数据，从而Bias较大，但是正因为没有过度拟合训练数据，Variance也较小。</p>
<p>这个图是我看到比较清楚明了的了：</p>
<p><img src="http://wx4.sinaimg.cn/mw690/006cxA6Hgy1fp5h42bf9sj30jg0j8t9f.jpg" alt=""></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/02/14/LDA知识点总结/"><span>线性判别分析是什么</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/02/14/LDA知识点总结/" rel="bookmark">
        <time class="entry-date published" datetime="2017-02-14T06:15:21.000Z">
          2017-02-14
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="LDA知识点总结"><a href="#LDA知识点总结" class="headerlink" title="LDA知识点总结"></a>LDA知识点总结</h2><blockquote>
<p>这个LDA不是NLP里的主题模型，是线性判别分析奥</p>
</blockquote>
<p>LDA的全称是Linear Discriminant Analysis（线性判别分析），是一种supervised learning。因为是由Fisher在1936年提出的，所以也叫Fisher’s Linear Discriminant。</p>
<p>一句话读懂LDA：<strong>投影后类内方差最小，类间方差最大</strong></p>
<p>LDA通常作为数据预处理阶段的降维技术，其目标是将数据投影到低维空间来避免维度灾难（curse of dimensionality）引起的过拟合，同时还保留着良好的可分性。也可以说它是一种分类算法，通过对历史数据进行投影，以保证投影后同一类别的数据尽量靠近，不同类别的数据尽量分开。并生成线性判别模型对新生成的数据进行分离和预测。所以我们能看到它是一种有效的特征抽取方法。使用这种方法能够使投影后模式样本的类间散布矩阵最大，并且同时类内散布矩阵最小。就是说，它能够保证投影后模式样本在新的空间中有最小的类内距离和最大的类间距离，即模式在该空间中有最佳的可分离性。</p>
<p>具体LDA分类基本思想：假设各个类别的样本数据符合高斯分布，这样利用LDA进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。</p>
<p>关于具体公式就不手打了，贴几张图形象的表示一下它的原理：</p>
<p><img src="http://wx1.sinaimg.cn/mw690/006cxA6Hgy1fp5f20x8vij31cy0es76e.jpg" alt=""></p>
<p>从直观上可以看出，右图要比左图的投影效果好，因为右图的黑色数据和蓝色数据各个较为集中，且类别之间的距离明显。左图则在边界处数据混杂。以上就是LDA的主要思想了，当然在实际应用中，我们的数据是多个类别的，我们的原始数据一般也是超过二维的，投影后的也一般不是直线，而是一个低维的超平面。</p>
<h3 id="PCA和LDA"><a href="#PCA和LDA" class="headerlink" title="PCA和LDA"></a>PCA和LDA</h3><p>PCA（主成分分析）和LDA（线性判别分析）有很多的相似点，其本质是要将初始样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</p>
<p>首先我们看看相同点：</p>
<p>1）两者均可以对数据进行降维。</p>
<p>2）两者在降维时均使用了矩阵特征分解的思想。</p>
<p>3）两者都假设数据符合高斯分布。</p>
<p>我们接着看看不同点：</p>
<p>1）LDA是有监督的降维方法，而PCA是无监督的降维方法</p>
<p>2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。</p>
<p>3）LDA除了可以用于降维，还可以用于分类。</p>
<p>4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。</p>
<h3 id="LDA优缺点分析"><a href="#LDA优缺点分析" class="headerlink" title="LDA优缺点分析"></a>LDA优缺点分析</h3><p>LDA算法的主要优点有：</p>
<p>1）在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。</p>
<p>2）LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。</p>
<p>LDA算法的主要缺点有：</p>
<p>1）LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。</p>
<p>2）LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。</p>
<p>3）LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。</p>
<p>4）LDA可能过度拟合数据。</p>
<p>scikit-learn中就能直接用LDA（sklearn.discriminant_analysis.LinearDiscriminantAnalysis）。一般来说，如果我们的数据是有类别标签的，那么优先选择LDA去尝试降维；当然也可以使用PCA做很小幅度的降维去消去噪声，然后再使用LDA降维。如果没有类别标签，那么肯定PCA是最先考虑的一个选择了。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/01/17/线性回归/"><span>逻辑回归总结</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/01/17/线性回归/" rel="bookmark">
        <time class="entry-date published" datetime="2017-01-17T02:37:21.000Z">
          2017-01-17
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>总结了一下最近看的知识和笔记</p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p><img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5bva7dh9j313a0n8wg7.jpg" alt=""><br><img src="http://wx4.sinaimg.cn/mw690/006cxA6Hgy1fp5bvryhdcj313e0nrwn6.jpg" alt=""><br><img src="http://wx3.sinaimg.cn/mw690/006cxA6Hgy1fp5bvxa0qwj31360an0te.jpg" alt=""><br><img src="http://wx3.sinaimg.cn/mw690/006cxA6Hgy1fp5bvnh1loj312x0du3zm.jpg" alt=""></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>线性回归、岭回归、lasso回归和多项式回归模型。这些模型都是广义线性回归模型的具体形式，广义线性回归是一种灵活的框架，比普通线性回归要求更少的假设。似乎工业界中常用到逻辑回归，那就来看看广义线性回归模型的具体形式的另一种形式，逻辑回归（logistic regression）。</p>
<p>据说LR简单、解释性好、计算速度快，和前面的模型不同，逻辑回归是用来做分类任务的。分类任务的目标是找一个函数，把观测值匹配到相关的类和标签上。学习算法必须用成对的特征向量和对应的标签来估计匹配函数的参数，从而实现更好的分类效果。简单来说， 逻辑回归是一种用于解决二分类（0 or 1）问题的机器学习方法，用于估计某种事物的可能性。这里用的是“可能性”，而非数学上的“概率”，logisitc回归的结果并非数学定义中的概率值，不可以直接当做概率值来用。该结果往往用于和其他特征值加权求和，而非直接相乘。</p>
<p>普通的线性回归假设响应变量呈正态分布，也称为高斯分布（Gaussian distribution ）或钟形曲线（bell curve）。正态分布数据是对称的，且均值，中位数和众数（mode）是一样的。很多自然现象都服从正态分布。如果响应变量不服从正态分布，就要用另外一种联连函数（解释变量到响应变量）了。所以说，逻辑回归假设因变量 y 服从<strong>伯努利分布</strong>，而线性回归假设因变量 y 服从<strong>高斯分布</strong>。</p>
<p>在逻辑回归里，响应变量描述了类似于掷一个硬币结果为正面的可能性。如果响应变量等于或超过了指定的临界值，预测结果就是正面，否则预测结果就是反面。响应变量是一个像线性回归中的解释变量构成的函数表示，称为逻辑函数（logistic function）。一个值在[0, 1]之间的逻辑函数如下所示<br><img src="http://wx1.sinaimg.cn/mw690/006cxA6Hgy1fp5cf5yah2j31dq0480st.jpg" alt=""><br>上式即为Sigmoid函数，是一个s形的曲线，它的取值在[0, 1]之间，在远离0的地方函数的值会很快接近0或者1。它的这个特性对于解决二分类问题十分重要。选择0.5作为阈值是一个一般的做法，实际应用时特定的情况可以选择不同阈值，如果对正例的判别准确性要求高，可以选择阈值大一些，对正例的召回要求高，则可以选择阈值小一些。</p>
<p>因此与线性回归有很多相同之处，去除Sigmoid映射函数的话，逻辑回归算法就是一个线性回归。可以说，逻辑回归是以线性回归为理论支持的，但是逻辑回归通过Sigmoid函数引入了非线性因素，因此可以轻松处理0/1分类问题。</p>
<p>其他基础知识就不做更多介绍，因为有很多资料，再讲几个我认为比较重要的点：</p>
<h3 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h3><p><code>什么是损失函数？</code></p>
<p>概况来讲，任何能够衡量模型预测出来的值与真实值之间的差异的函数都可以叫做代价函数 ,因此训练参数的过程就是不断改变θ，从而得到更小的损失函数的过程，在优化参数θ的过程中，最常用的方法是梯度下降。关于求解的优化方法以及代价函数的一些常见形式以后再开一篇仔细写写，现在先讲一下逻辑回归和线性回归的代价函数：<br>在线性回归中，最常用的是均方误差(Mean squared error)，即<br><img src="http://wx3.sinaimg.cn/mw690/006cxA6Hgy1fp5d5kgftxj31kw0bc769.jpg" alt=""><br>在逻辑回归中，最常用的是代价函数是交叉熵(Cross Entropy)，交叉熵是一个常见的代价函数，在神经网络中也会用到。下面是找到的《神经网络与深度学习》一书对交叉熵的解释：</p>
<p>交叉熵是对「出乎意料」的度量。神经元的目标是去计算函数x→y=y(x)。但是我们让它取而代之计算函数x→a=a(x)。假设我们把a当作y等于1的概率，1−a是y等于0的概率。那么，交叉熵衡量的是我们在知道y的真实值时的平均「出乎意料」程度。当输出是我们期望的值，我们的「出乎意料」程度比较低；当输出不是我们期望的，我们的「出乎意料」程度就比较高。香农信息量用来度量不确定性的大小：一个事件的香农信息量等于0，表示该事件的发生不会给我们提供任何新的信息，例如确定性的事件，发生的概率是1，发生了也不会引起任何惊讶；当不可能事件发生时，香农信息量为无穷大，这表示给我们提供了无穷多的新信息，并且使我们无限的惊讶。</p>
<p>根据交叉熵定义的损失函数如下：</p>
<p><img src="http://wx3.sinaimg.cn/mw690/006cxA6Hgy1fp5d5odj9sj31kw04h3yy.jpg" alt=""></p>
<p>其实这个式子很好理解，即从式中可以看出， y=1 ，当预测值 h<em>\theta(x)=1  时，可以看出代价h</em>\theta(x)=\frac{1}{1+e^{-\theta^Tx}}函数 C(\theta) 的值为0，这正是我们希望的。如果预测值 h_\theta(x)=1 即 P(y=1|x;\theta)=0 ,意思是预测 y=1 的概率为0，但是事实上 y=1 ，因此代价函数 C(\theta)=\infty 相当于给学习算法一个惩罚。</p>
<h3 id="逻辑回归和朴素贝叶斯有什么区别？"><a href="#逻辑回归和朴素贝叶斯有什么区别？" class="headerlink" title="逻辑回归和朴素贝叶斯有什么区别？"></a>逻辑回归和朴素贝叶斯有什么区别？</h3><p><code>贝叶斯公式 + 条件独立假设 = 朴素贝叶斯方法</code></p>
<p>首先朴素贝叶斯里有一个很强的假设，就是条件独立假设。朴素贝叶斯作分类的时候，简单的说最终目的就是判断P（X=1）/P（X=0） &gt; 1 就好了，但是实际上除法并不好，容易产生过小的数值，发生underflow，所以我们两边同时取对数log函数。逻辑回归实际上是用线性回归模型的预测结果去逼近后验概率的逻辑发生比，能推导出朴素贝叶斯里有求和项，逻辑回归中也有求和项，并且表达式非常相似，但二者还是有区别的，用两种方法求出来的权重是不一样。产生差别的原因在于朴素贝叶斯方法的条件独立假设，因此，朴素贝叶斯可以不使用梯度下降，而直接通过统计每个特征的逻辑发生比来当权重，而逻辑回归的条件假设并不成立，通过梯度下降法可以得到特征之间的耦合信息，从而得到相应的权重。</p>
<p>此外，进一步说，朴素贝叶斯中的对数线性和Logistic回归中的对数线性作用不同。朴素贝叶斯中的log只是因为工程上的需要，而Logistic regression中的log可以有很多种解释。比方说从广义线性模型的角度解释的话，这个对数线性是因为lr把 P(y|x) 假设成一个二项分布（对于多分类是多项分布），而二项分布可以写成exponential family的标准形式。这也是LR的本质了，说到指数族分布,区别于指数分布，统计中很多熟悉的概率分布都是指数族分布的特定形式，（伯努利分布，高斯分布，多项分布），</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2016/12/28/解决python报错/"><span>Python 问题（二）</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/12/28/解决python报错/" rel="bookmark">
        <time class="entry-date published" datetime="2016-12-28T01:15:21.000Z">
          2016-12-28
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h1 id="python-mpl-toolkits-installation-issue"><a href="#python-mpl-toolkits-installation-issue" class="headerlink" title="python mpl_toolkits installation issue"></a>python mpl_toolkits installation issue</h1><p>OSError: [Errno 1] Operation not permitted: ‘/tmp/pip-nIfswi-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info’</p>
<blockquote>
<p>import missingno时候出现ImportError: No module named mpl_toolkits.axes_grid1</p>
</blockquote>
<p>加入</p>
<blockquote>
<p>import mpl_toolkits</p>
</blockquote>
<p>报错：</p>
<blockquote>
<p>Could not find a version that satisfies the requirement mpl_toolkits (from versions: )<br>No matching distribution found for mpl_toolkits  </p>
</blockquote>
<p>解决如下：</p>
<pre><code>sudo -H pip install awscli --upgrade --ignore-installed six
sudo pip install --ignore-installed six
sudo pip install --ignore-installed matplotlib
</code></pre>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2016/12/25/pandas安装问题/"><span>Python问题</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/12/25/pandas安装问题/" rel="bookmark">
        <time class="entry-date published" datetime="2016-12-25T12:35:21.000Z">
          2016-12-25
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h1 id="解决-Mac-pip-Error-Errno-1-Operation-not-permitted"><a href="#解决-Mac-pip-Error-Errno-1-Operation-not-permitted" class="headerlink" title="解决 Mac pip Error: [Errno 1] Operation not permitted"></a>解决 Mac pip Error: [Errno 1] Operation not permitted</h1><p>安装pandas包的时候出现报错：</p>
<pre><code>Installing collected packages: numpy, pandas
Found existing installation: numpy 1.8.0rc1
DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
Uninstalling numpy-1.8.0rc1:
Exception:
Traceback (most recent call last):
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main
status = self.run(options, args)
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run
prefix=options.prefix_path,
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install
requirement.uninstall(auto_confirm=True)
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall
paths_to_remove.remove(auto_confirm)
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove
renames(path, new_path)
File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames
shutil.move(old, new)
File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move
copy2(src, real_dst)
File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2
copystat(src, dst)
File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat
os.chflags(dst, st.st_flags)

OSError: [Errno 1] Operation not permitted: &apos;/tmp/pip-bXMbsV-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info&apos;
</code></pre><p>解决如下：</p>
<pre><code>$ pip install --upgrade pip

$ sudo pip install numpy --upgrade --ignore-installed
</code></pre>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2016/12/11/mac+hexo/"><span>博客搭建</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/12/11/mac+hexo/" rel="bookmark">
        <time class="entry-date published" datetime="2016-12-11T11:35:21.000Z">
          2016-12-11
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h1 id="mac环境下hexo博客搭建"><a href="#mac环境下hexo博客搭建" class="headerlink" title="mac环境下hexo博客搭建"></a>mac环境下hexo博客搭建</h1><hr>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ul>
<li><p><strong>Node.js</strong></p>
<p>官网下载安装</p>
</li>
<li><p><strong>git</strong></p>
<p>appstore下载安装Xcode即可</p>
</li>
</ul>
<h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2><ul>
<li><p><strong>执行指令</strong></p>
<p><code>sudo npm install -g hexo</code></p>
</li>
<li><p><strong>初始化</strong></p>
<p><code>hexo init blog</code></p>
</li>
<li><p><strong>安装npm</strong></p>
<p><code>npm install</code></p>
</li>
<li><p><strong>开启hexo服务器</strong></p>
<p><code>hexo s</code></p>
</li>
</ul>
<h2 id="关联github"><a href="#关联github" class="headerlink" title="关联github"></a>关联github</h2><ul>
<li><p><strong>登陆github账号，新建仓库</strong></p>
<p><em>仓库名必须是github用户名.github.io 否则会报错404</em></p>
<p>打开blog文件中_config.yml，修改最后部分：</p>
<p><code>deploy:
type: git
repository: https://github.com/&quot;你自己的用户名“/”你自己用户名“.github.io.git
branch: master</code></p>
<blockquote>
<p>注意冒号后面一定要接空格</p>
</blockquote>
<p><code>hexo g</code></p>
<p><code>hexo d</code></p>
<p>即可生成网页，<a href="https://用户名.github.io，可以访问并看到你的博客" target="_blank" rel="noopener">https://用户名.github.io，可以访问并看到你的博客</a></p>
<p>如果报错：</p>
<p><code>npm install hexo-deployer-git --save</code></p>
<p>重复</p>
</li>
<li><p><strong>添加ssh keys到github</strong></p>
<p><code>ls -al ~/.ssh</code></p>
<p><code>ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</code></p>
<p><em>注意密码要大于五个字符</em></p>
<p>打开~/.ssh/id_rsa.pub文件，拷贝内容至Github –&gt; Settings –&gt; SSH keys –&gt; add SSH key:</p>
</li>
<li><p><strong>发布文章</strong></p>
<p><code>hexo new &quot;postName&quot;</code></p>
<p>名为postName.md的文件会建在目录/blog/source/_posts下, 此刻我正在用macdown编辑.md文件</p>
<p>cd到blog文件夹下</p>
<p><code>hexo g</code></p>
<p><code>hexo d</code></p>
</li>
</ul>
<h2 id="更换theme"><a href="#更换theme" class="headerlink" title="更换theme"></a>更换theme</h2><ul>
<li><p><strong>最重要的就是更换主题啦！</strong></p>
<p><a href="https://hexo.io/themes/" target="_blank" rel="noopener">hexo官网</a> 可以在官网上看自己喜欢的主题💕</p>
<p>切记不要在 hexo server 运行的时候安装主题。因为文件的改动会导致 Hexo server 重新生成网站，如果有些文件还没下载完 或者 文件内的语法有问题，就会导致 Hexo server 报错，之后再刷新网页的话就什么也打不开，会报很奇怪的错误。</p>
<p><code>git clone https://github.com.....&quot;这里是你喜欢主题的github链接&quot;</code></p>
<blockquote>
<p>然后一定要在blog文件夹下把_config.yml里的theme改成你git的主题名</p>
</blockquote>
<p>cd到blog目录</p>
<p><code>hexo clean</code></p>
<p><code>hexo g</code></p>
<p><code>hexo d</code></p>
<p>我第一次更换主题的时候出现了一些错误，发现是没有在blog目录执行<br>npm install hexo-renderer-ejs –save</p>
</li>
</ul>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>




<nav class="pagination">
  
  
</nav>
    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2018 Yang He
    
  </p>
</footer>
    
  </div>
</div>
</body>
</html>