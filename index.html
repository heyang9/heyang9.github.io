<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>呜呜部落格(•̀ᴗ•́)و ̑̑</title>

  
  <meta name="author" content="Yang He">
  

  

  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="呜呜部落格(•̀ᴗ•́)و ̑̑"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="呜呜部落格(•̀ᴗ•́)و ̑̑" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">呜呜部落格(•̀ᴗ•́)و ̑̑</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    
  <article>

  
    
    <h3 class="article-title"><a href="/2018/01/12/未命名/"><span>一个有意思的Deep Learning笔记</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/01/12/未命名/" rel="bookmark">
        <time class="entry-date published" datetime="2018-01-12T01:22:21.000Z">
          2018-01-12
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <iframe src=" /Users/eve/Downloads/introdl.pdf" style="width:300px; height:100px;" frameborder="0"></iframe>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/12/02/XGBoost原理/"><span>集成算法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/12/02/XGBoost原理/" rel="bookmark">
        <time class="entry-date published" datetime="2017-12-02T02:22:21.000Z">
          2017-12-02
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="RF、GBDT和xgboost"><a href="#RF、GBDT和xgboost" class="headerlink" title="RF、GBDT和xgboost"></a>RF、GBDT和xgboost</h2><h3 id="RF"><a href="#RF" class="headerlink" title="RF"></a>RF</h3><p>bagging很好理解的。从M个训练样本中随机选取m个样本，从N个特征中随机选取n个特征，然后建立一颗决策树。这样训练出T棵树后，让这k颗树对测试集进行投票产生决策值。RF是一种bagging的思路。可以并行化处理。</p>
<p>随机森林的优点较多，简单总结：1、在数据集上表现良好，相对于其他算法有较大的优势（训练速度、预测准确度）；2、能够处理很高维的数据，并且不用特征选择，而且在训练完后，给出特征的重要性；3、容易做成并行化方法。<br>RF的缺点：在噪声较大的分类或者回归问题上回过拟合。</p>
<p>我用随机森林做异常检测的效果还是不错的。</p>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>总共构建T棵树。当构建到第t棵树的时候，需要对前t-1棵树对训练样本分类回归产生的残差进行拟合。每次构建树的方式以及数据集一样，只不过拟合的目标变成了t-1棵树输出的残差。不可并行化处理。从CART来的，GBDT是回归树，当然也能分类，其实做分类的时候和Adaboost有点像，就是给个权重。GBDT中的决策树是个弱模型，深度较小一般不会超过5，叶子节点的数量也不会超过10，对于生成的每棵决策树乘上比较小的缩减系数（学习率&lt;0.1），有些GBDT的实现加入了随机抽样（subsample 0.5&lt;=f &lt;=0.8）提高模型的泛化能力。通过交叉验证的方法选择最优的参数。</p>
<p>GBDT与传统的Boosting区别较大，它的每一次计算都是为了减少上一次的残差，而为了消除残差，我们可以在残差减小的梯度方向上建立模型,所以说，在GradientBoost中，每个新的模型的建立是为了使得之前的模型的残差往梯度下降的方法，与传统的Boosting中关注正确错误的样本加权有着很大的区别。<br>在GradientBoosting算法中，关键就是利用<strong>损失函数的负梯度方向在当前模型的值作为残差的近似值</strong>，进而拟合一棵CART回归树。<br>GBDT的会累加所有树的结果，而这种累加是无法通过分类完成的，</p>
<blockquote>
<p>类比梯度下降会很好理解</p>
</blockquote>
<p>GBDT的性能在RF的基础上又有一步提升，因此其优点也很明显，1、它能灵活的处理各种类型的数据；2、在相对较少的调参时间下，预测的准确度较高。<br>当然由于它是Boosting，因此基学习器之前存在串行关系，难以并行训练数据。</p>
<h3 id="XGBOOST"><a href="#XGBOOST" class="headerlink" title="XGBOOST"></a>XGBOOST</h3><p>总共构建T颗树。当构建到第t颗树的时候，需要对前t-1颗树对训练样本分类回归产生的残差进行拟合。每次拟合产生新的树的时候，遍历所有可能的树，并选择使得目标函数值（cost）最小的树。但是这样在实践中难以实现，因此需要将步骤进行分解，在构造新的树的时候，每次只产生一个分支，并选择最好的那个分支。如果产生分支的目标函数值（cost）比不产生的时候大或者改进效果不明显，那么就放弃产生分支（相当于truncate，截断）。可以并行化处理，效率比GBDT高，效果比GBDT好。</p>
<h3 id="区别和联系"><a href="#区别和联系" class="headerlink" title="区别和联系"></a>区别和联系</h3><p>Xgboost是GB算法的高效实现，xgboost中的基学习器除了可以是CART（gbtree）也可以是线性分类器（gblinear）。 </p>
<pre><code>(1). xgboost在目标函数中显示的加上了正则化项，基学习为CART时，正则化项与树的叶子节点的数量T和叶子节点的值有关。 
(2). GB中使用Loss Function对f(x)的一阶导数计算出伪残差用于学习生成fm(x)，xgboost不仅使用到了一阶导数，还使用二阶导数。 
(3). 上面提到CART回归树中寻找最佳分割点的衡量标准是最小化均方差，xgboost寻找分割点的标准是最大化，lamda，gama与正则化项相关。
</code></pre><p>有一些比较难理解的点：</p>
<blockquote>
<p>1、在寻找最佳分割点时，考虑传统的枚举每个特征的所有可能分割点的贪心法效率太低，xgboost实现了一种近似的算法。大致的思想是根据百分位法列举几个可能成为分割点的候选者，然后从候选者中根据上面求分割点的公式计算找出最佳的分割点。<br>2、xgboost<strong>考虑了训练数据为稀疏值的情况，可以为缺失值或者指定的值指定分支的默认方向，这能大大提升算法的效率</strong>，paper提到50倍。<br>特征列排序后以块的形式存储在内存中，在迭代中可以重复使用；虽然boosting算法迭代必须串行，但是在处理每个特征列时可以做到并行。<br>按照特征列方式存储能优化寻找最佳的分割点，但是当以行计算梯度数据时会导致内存的不连续访问，严重时会导致cache miss，降低算法效率。paper中提到，可先将数据收集到线程内部的buffer，然后再计算，提高算法的效率。<br>3、xgboost 还考虑了当数据量比较大，内存不够时怎么有效的使用磁盘，主要是结合多线程、数据压缩、分片的方法，尽可能的提高算法的效率。</p>
</blockquote>
<p>关于GBDT和XGboost还是蛮简单的：</p>
<p>GBDT和随机森林的相同点：<br>1、都是由多棵树组成<br>2、最终的结果都是由多棵树一起决定</p>
<p><code>GBDT和随机森林的不同点：</code> </p>
<p>1、组成随机森林的树可以是分类树，也可以是回归树；而GBDT只由回归树组成<br>2、组成随机森林的树可以并行生成；而GBDT只能是串行生成<br>3、对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来<br>4、随机森林对异常值不敏感，GBDT对异常值非常敏感<br>5、随机森林对训练集一视同仁，GBDT是基于权值的弱分类器的集成<br>6、随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能</p>
<p><code>GBDT和XGBoost区别</code></p>
<p>1、传统的GBDT以CART树作为基学习器，XGBoost还支持线性分类器，这个时候XGBoost相当于L1和L2正则化的逻辑斯蒂回归（分类）或者线性回归（回归）。 </p>
<p>2、传统的GBDT在优化的时候只用到一阶导数信息，XGBoost则对代价函数进行了二阶泰勒展开，得到一阶和二阶导数。 </p>
<p>3、XGBoost在代价函数中加入了正则项，用于控制模型的复杂度。从权衡方差偏差来看，它降低了模型的方差，使学习出来的模型更加简单，放置过拟合，这也是XGBoost优于传统GBDT的一个特性。 </p>
<p>4、Shrinkage（缩减），相当于学习速率（XGBoost中的eta）。XGBoost在进行完一次迭代时，会将叶子节点的权值乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。（GBDT也有学习速率）。 </p>
<p>5、列抽样。XGBoost借鉴了随机森林的做法，支持列抽样，不仅防止过 拟合，还能减少计算。</p>
<p>6、对缺失值的处理。对于特征的值有缺失的样本，XGBoost还可以自动 学习出它的分裂方向。 </p>
<p>7、XGBoost工具支持并行。Boosting不是一种串行的结构吗?怎么并行 的？注意XGBoost的并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。XGBoost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），XGBoost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代 中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<h2 id="XGBoost原理"><a href="#XGBoost原理" class="headerlink" title="XGBoost原理"></a>XGBoost原理</h2><p>GBDT在函数空间中利用梯度下降法进行优化，XGBoost在函数空间中用牛顿法进行优化。</p>
<p>实际上GBDT泛指所有梯度提升树算法，包括XGBoost，它也是GBDT的 一种变种，这里为了区分它们，GBDT特指“Greedy Function Approximation:A Gradient Boosting Machine”里提出的算法，它只用了 一阶导数信息。</p>
<p><a href="http://djjowfy.com/2017/08/01/XGBoost的原理/" target="_blank" rel="noopener">一个写的蛮好的博客链接</a></p>
<p>不总结啦。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/10/08/ARIMA😛/"><span>利用ARIMA模型做时间序列预测</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/10/08/ARIMA😛/" rel="bookmark">
        <time class="entry-date published" datetime="2017-10-08T01:22:21.000Z">
          2017-10-08
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="ARIMA😛"><a href="#ARIMA😛" class="headerlink" title="ARIMA😛"></a>ARIMA😛</h2><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>时间序列，就是按时间顺序排列的，随时间变化的数据序列。我从自己实验平台上采的上位机和设备之间的通信包，按packets/s做数据就是时间序列。因为这个环境比较特殊，跟通信过程和应用层协议有关系，这里就不多说了，因为不是传统网络包，所以前期还是做了一些分析的，结果是这些数据是周期性的，但是不平稳，总之是可以做很多东西的。</p>
<p>随机过程的特征有均值、方差、协方差等。<br>如果随机过程的特征随着时间变化，则此过程是非平稳的；相反，如果随机过程的特征不随时间而变化，就称此过程是平稳的。非平稳时间序列分析时，若导致非平稳的原因是确定的，可以用的方法主要有趋势拟合模型、季节调整模型、移动平均、指数平滑等方法。<br>若导致非平稳的原因是随机的，方法主要有ARIMA（autoregressive integrated moving average）及自回归条件异方差模型等。</p>
<p>ARIMA，就是AR，I，MA的结合。ARIMA(p,d,q)模型，其中 d 是差分的阶数，用来得到平稳序列。</p>
<p>AR是自回归, p为相应的自回归项。MA为移动平均，q为相应的移动平均项数。ARIMA和ARMA的区别，就是公式左边的x变成差分算子，保证数据的稳定性。一般取两阶以下就好了。</p>
<p>贴公式：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1667471-e3570dff8b96abda.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/515" alt=""></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1667471-994e75bd9e86802c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/517" alt=""></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1667471-9fefb203841154f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/617" alt=""></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1667471-80aa172908765c87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/488" alt=""></p>
<h3 id="上手"><a href="#上手" class="headerlink" title="上手"></a>上手</h3><p>ARIMA模型运用的基本流程有几下几步：</p>
<pre><code>数据可视化，识别平稳性。
对非平稳的时间序列数据，做差分，得到平稳序列。
建立合适的模型。
平稳化处理后，若偏自相关函数是截尾的，而自相关函数是拖尾的，则建立AR模型；
若偏自相关函数是拖尾的，而自相关函数是截尾的，则建立MA模型；
若偏自相关函数和自相关函数均是拖尾的，则序列适合ARMA模型。
模型的阶数在确定之后，对ARMA模型进行参数估计，比较常用是最小二乘法进行参数估计。
假设检验，判断（诊断）残差序列是否为白噪声序列。
利用已通过检验的模型进行预测。
</code></pre><p>1.数据的平稳性处理<br>ARIMA模型建模时，首先采用ADF（Augmented Dickey-Fuller）单位根检验来判断数据的平稳性。通常可以画出时间序列的散点图或折线图，来对所研究的时间序列进行大致的平稳性判断。对非平稳的时间序列，一般取对数处理或进行差分处理，然后判断修正后的数据序列的平稳性。若采取差分的形式，此时进行差分的次数就是ARIMA(p,d,q)模型中的阶数d。在差分运算过程中，阶数并不是越大越好，差分运算的过程是信息加工提取的过程，因此，一般差分次数不超过2次。时间序列数据被平稳化处理后，ARIMA(p,d,q)模型就转化为ARMA(p,q)模型。</p>
<p>2.建立模型<br>通常在时间序列分析中，采用自相关函数（ACF）、偏自相关函数（PACF）来判别ARMA(p,q)模型的系数和阶数。自相关函数(ACF)描述时间序列观测值与其过去的观测值之间的线性相关性。偏自相关函数(PACF)描述在给定中间观测值的条件下时间序列观测值与其过去的观测值之间的线性相关性。<br><img src="http://img.blog.csdn.net/20150602093858686?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYXNwaXJpbnZhZ3JhbnQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>这个表基本上就够用啦</p>
<p>3.参数估计<br>时间序列分析模型的阶数在确定之后，然后应当对ARMA模型进行参数估计。比较常用是最小二乘法进行参数估计，但是在所有的时间序列模型中，MA模型的参数估计相对比较困难，因此，尽量避免使用高阶的MA模型和ARMA模型。</p>
<p>4.模型验证<br>通过上述步骤后，应对通过模型取得的估计结果进行检验与诊断，以验证所选用的模型是否合适。这一过程主要检验所拟合的时间序列模型是否客观合理。针对模型的合理性检验，通常从两个方面进行判断：1、要验证所拟合的时间序列<br>模型的参数估计值是否有显著性；2、要验证所拟合的时间序列模型的残差序列是否是白噪声序列，即残差序列的独立性检验。残差序列可由估计出来的模型计算得到，如果残差序列的自相关函数不显著非零，可以认为是独立的。若这两项验证通过，则认为该模型是合理的，否则，应重新选取模型，上述步骤，选出有效的模型，然后应用该模型进行预测。</p>
<p>这里不把我对工控数据的arima分析贴出来了，其实比较一下仔细分析选的模型和autoarima的特性还是蛮有趣的</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/08/02/git账号/"><span>查看本地git的账号是否是目前登陆的邮箱</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/08/02/git账号/" rel="bookmark">
        <time class="entry-date published" datetime="2017-08-02T01:22:21.000Z">
          2017-08-02
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>我的GitHub账号很乱。感觉</p>
<p>我查了一下，很多人出现跟我类似的问题，都在问为什么自己明明有干嘛干嘛啊，为什么没有绿格子，基本上解决办法就是本地看一下git账号邮箱啊用户名啊是什么就能解决了。</p>
<p><code>$ git config --global user.name &quot;John Doe&quot;</code></p>
<p><code>$ git config --global user.email johndoe@example.com</code></p>
<p>这个是一开始的配置，可能大家配置的时候很不经意 就填了其他的。。像我这种有好几个邮箱的人很多吧。这个其实蛮关键的，因为以后你所有的项目都会默认使用这里配置的用户信息。</p>
<p>为什么没有绿格子呢，看一下配置信息就好啦</p>
<p><code>$ git config --list</code></p>
<p>不是自己登陆的邮箱账号的话就改吧</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/07/27/略谈EM算法/"><span>EM算法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/07/27/略谈EM算法/" rel="bookmark">
        <time class="entry-date published" datetime="2017-07-27T01:22:21.000Z">
          2017-07-27
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="略谈EM算法"><a href="#略谈EM算法" class="headerlink" title="略谈EM算法"></a>略谈EM算法</h2><p>目前虽然没有用到这个的项目，但是毕竟是经典算法，而且跟概率相关的对于我而言都比较绕，就仔细琢磨琢磨啦。</p>
<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>先说最大似然估计好了，我觉得这个蛮好理解的：</p>
<p>通俗的说：现在已经拿到了很多个样本（你的数据集中所有因变量），这些样本值已经实现，最大似然估计就是去找到那个（组）参数估计值，使得前面已经实现的样本值发生概率最大。这时是求样本所有观测的联合概率最大化，是个连乘积，只要取对数，就变成了线性加总。此时通过对参数求导数，并令一阶导数为零，就可以通过解方程（组），得到最大似然估计值。</p>
<p><img src="http://img.blog.csdn.net/20170528003838359" alt=""></p>
<p>实际中为了便于分析，定义了对数似然函数：</p>
<p><img src="http://img.blog.csdn.net/20170528003844453" alt=""></p>
<p><img src="http://img.blog.csdn.net/20170528003850144" alt=""></p>
<p>求最大似然估计量的一般步骤：</p>
<pre><code>（1）写出似然函数；

（2）对似然函数取对数，并整理；

（3）求导数；

（4）解似然方程。
</code></pre><p>最大似然估计的特点：</p>
<pre><code>1.比其他估计方法更加简单；

2.收敛性：无偏或者渐近无偏，当样本数目增加时，收敛性质会更好；

3.如果假设的类条件概率模型正确，则通常能获得较好的结果。但如果假设模型出现偏差，将导致非常差的估计结果。
</code></pre><h3 id="贝叶斯决策"><a href="#贝叶斯决策" class="headerlink" title="贝叶斯决策"></a>贝叶斯决策</h3><p>都说到极大似然了，继续讲一下贝叶斯决策吧。也有很多科普是先从贝叶斯决策引出极大似然的。</p>
<p><img src="http://img.blog.csdn.net/20170528002022807" alt=""></p>
<p>我们要求的是后验概率，就得先知道先验概率和似然（类条件概率）。这里先验概率估计较简单，1、每个样本所属的自然状态都是已知的（有监督学习）；2、依靠经验；3、用训练样本中各类出现的频率估计。类条件概率的估计（非常难），原因包括：概率密度函数包含了一个随机变量的全部信息；样本数据可能不多；特征向量x的维度可能很大等等。总之要直接估计类条件概率的密度函数很难。解决的办法就是，把估计完全未知的概率密度转化为估计参数。这里就将概率密度估计问题转化为参数估计问题，极大似然估计就是一种参数估计方法。</p>
<h3 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h3><p>M算法当做最大似然估计的拓展，解决难以给出解析解的最大似然估计（MLE）问题。EM算法引入了隐变量。什么是隐变量呢，比如你知道A是高斯分布，和一些样本，就能估计它的参数，B也是。但是如果A，B是混合的，就不太好估计，因为抽取得到的每个样本都不知道是从哪个分布抽取的，（直观上是这样，公式推导结果也是如此，出现了log在两个求和符号之间的情况）</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28X%3B%5Ctheta%29%3D%5Csum_%7Bk%3D1%7D%5EK%5Cpi_kN%28x%3B+%5Cmu_k%2C+%5Csigma_k%29%3D%5Csum_ZP%28Z%3B%5Cpi%29P%28X%7CZ%3B%5Cmu%2C%5Csigma%29" alt=""></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Ctheta%5E%2A+%26%3D+%5Carg%5Cmax_%5Ctheta+%5Csum_X+logP%28X%3B%5Ctheta%29+%5C%5C+%26%3D%5Carg%5Cmax_%5Ctheta+%5Csum_X+log+%5Csum_ZP%28Z%3B%5Cpi%29P%28X%7CZ%3B%5Cmu%2C%5Csigma%29+%5C%5C+%26%3D%5Carg%5Cmax_%5Ctheta+%5Csum_X+log+%5Csum_ZP%28X%2CZ%3B%5Ctheta%29+%5Cend%7Baligned%7D" alt=""></p>
<p>这时就需要EM算法。EM算法就是这样，假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。E步（求期望），第三步被称作M步（求极大化），于是EM算法就在不停的EM、EM、EM….，所以被叫做EM算法！使用EM的好处就是，分离不开，就不分离。用旧的变量来表达新的变量，一步步迭代，也能找到局部最优。其实也就坐标上升法，含有隐变量对数似然求导比较复杂，因此先固定参数求隐变量后验分布(E步)，然后固定隐变量求参数(M步)，交替进行。</p>
<p>举个非常棒的例子，看完基本上就能懂什么是EM算法，如下：</p>
<p><img src="https://pic1.zhimg.com/80/v2-a95770a0f41ed0873106d4a1f2dd6b7d_hd.jpg" alt=""></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/06/02/正则化的问题/"><span>L1正则化和L2正则化</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/06/02/正则化的问题/" rel="bookmark">
        <time class="entry-date published" datetime="2017-06-02T03:39:21.000Z">
          2017-06-02
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="正则化的问题"><a href="#正则化的问题" class="headerlink" title="正则化的问题"></a>正则化的问题</h2><p>先说一下范数是什么：<br><img src="https://upload-images.jianshu.io/upload_images/2027163-98307b25668cfa3a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/599" alt=""></p>
<blockquote>
<p>0范数，向量中非零元素的个数。<br>1范数，为绝对值之和。<br>2范数，就是通常意义上的模，表示某个向量中所有元素平方和再开根， 也就是欧几里得距离公式。</p>
</blockquote>
<p>也就是L1正则化和L2正则化，或者L1范数和L2范数</p>
<p>L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。Lasso回归的损失函数，式中加号后面一项α||w||1，即为L1正则化项。Ridge回归的损失函数，式中加号后面一项α||w||2^2,即为L2正则化项。</p>
<p><img src="http://img.blog.csdn.net/20160904184228158" alt=""></p>
<p><img src="http://img.blog.csdn.net/20160904184314333" alt=""></p>
<p>它们的作用：</p>
<p>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择<br>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</p>
<p>一般用l2正则化防止过拟合，那先讲它为什么能防止这个好了：</p>
<p>1.模型过于复杂是因为模型尝试去兼顾各个测试数据点， 导致模型函数如下图，处于一种动荡的状态， 每个点的到时在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。（很好理解吧，有的过拟合出来的曲线拐来拐去的，覆盖了每个点）如果发生过拟合， 参数θ一般是比较大的值， 加入惩罚项后， 只要控制λ的大小，当λ很大时，θ1到θn就会很小，即达到了约束数量庞大的特征的目的。</p>
<p>2.从贝叶斯的角度来分析， 正则化是为模型参数估计增加一个先验知识，先验知识会引导损失函数最小值过程朝着约束方向迭代。 L1正则是Laplace先验，L2是高斯先验。整个最优化问题可以看做是一个最大后验估计，其中正则化项对应后验估计中的先验信息，损失函数对应后验估计中的似然函数，两者的乘积即对应贝叶斯最大后验估计。（这一点有点难理解，需要假设参数先验分布之后推导）</p>
<p>然后是L1正则化。它的优良性质是能产生稀疏性，导致 W 中许多项变成零。 稀疏的解除了计算量上的好处之外，更重要的是更具有“可解释性”。L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。为什么要生成一个稀疏矩阵？稀疏矩阵指的是很多元素为0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。</p>
<p><img src="http://img.blog.csdn.net/20160904184428459" alt=""></p>
<p>上图是L1正则化的表示，这里简单假设w是二维，所以画出的图是这样的，图中等值线是J0<br>的等值线，黑色方形是L<br>函数的图形。在图中，当J0<br>等值线与L<br>图形首次相交的地方就是最优解。上图中J0<br>与L<br>在L<br>的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是(w1,w2)=(0,w)<br>。可以直观想象，因为L<br>函数有很多<em>突出的角</em>（二维情况下四个，多维情况下更多），J0<br>与这些角接触的机率会远大于与L<br>其它部位接触的机率，而在这些角上，会有很多权值等于0，这就是为什么L1正则化可以产生稀疏模型，进而可以用于特征选择。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/05/18/样本不平衡/"><span>机器学习中样本不平衡的解决办法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/05/18/样本不平衡/" rel="bookmark">
        <time class="entry-date published" datetime="2017-05-18T15:35:21.000Z">
          2017-05-18
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>##机器学习中样本不均衡怎么办？</p>
<p>手头在做的工业数据异常检测，就有这样的问题。或者说很多异常检测方向的基于机器学习的检测算法都会面临这个问题，异常样本太少，不处理的话，很容易被当成异常数据不处理了，所以要有解决办法。</p>
<p>通过过抽样和欠抽样解决样本不均衡：</p>
<blockquote>
<p>抽样是解决样本分布不均衡相对简单且常用的方法，包括过抽样和欠抽样两种。过抽样过抽样（也叫上采样、over-sampling）方法通过增加分类中少数类样本的数量来实现样本均衡，最直接的方法是简单复制少数类样本形成多条记录，这种方法的缺点是如果样本特征少而可能导致过拟合的问题；经过改进的过抽样方法通过在少数类中加入随机噪声、干扰数据或通过一定规则产生新的合成样本，例如SMOTE算法。欠抽样欠抽样（也叫下采样、under-sampling）方法通过减少分类中多数类样本的样本数量来实现样本均衡，最直接的方法是随机地去掉一些多数类样本来减小多数类的规模，缺点是会丢失多数类样本中的一些重要信息。总体上，过抽样和欠抽样更适合大数据分布不均衡的情况，尤其是第一种（过抽样）方法应用更加广泛。</p>
</blockquote>
<p>通过正负样本的惩罚权重解决样本不均衡:</p>
<blockquote>
<p>通过正负样本的惩罚权重解决样本不均衡的问题的思想是在算法实现过程中，对于分类中不同样本数量的类别分别赋予不同的权重（一般思路分类中的小样本量类别权重高，大样本量类别权重低），然后进行计算和建模。使用这种方法时需要对样本本身做额外处理，只需在算法模型的参数中进行相应设置即可。很多模型和算法中都有基于类别参数的调整设置，以scikit-learn中的SVM为例，通过在class_weight: {dict, ‘balanced’}中针对不同类别针对不同的权重，来手动指定不同类别的权重。如果使用其默认的方法balanced，那么SVM会将权重设置为与不同类别样本数量呈反比的权重来做自动均衡处理，计算公式为：n_samples / (n_classes * np.bincount(y))。如果算法本身支持，这种思路是更加简单且高效的方法。</p>
</blockquote>
<p> 通过组合/集成方法解决样本不均衡组合/集成方法:</p>
<blockquote>
<p> 指的是在每次生成训练集时使用所有分类中的小样本量，同时从分类中的大样本量中随机抽取数据来与小样本量合并构成训练集，这样反复多次会得到很多训练集和训练模型。最后在应用时，使用组合方法（例如投票、加权投票等）产生分类预测结果。例如，在数据集中的正、负例的样本分别为100和10000条，比例为1:100。此时可以将负例样本（类别中的大量样本集）随机分为100份（当然也可以分更多），每份100条数据；然后每次形成训练集时使用所有的正样本（100条）和随机抽取的负样本（100条）形成新的数据集。如此反复可以得到100个训练集和对应的训练模型。这种解决问题的思路类似于随机森林。在随机森林中，虽然每个小决策树的分类能力很弱，但是通过大量的“小树”组合形成的“森林”具有良好的模型预测能力。如果计算资源充足，并且对于模型的时效性要求不高的话，这种方法比较合适。</p>
</blockquote>
<p> 通过特征选择解决样本不均衡:</p>
<blockquote>
<p> 上述几种方法都是基于数据行的操作，通过多种途径来使得不同类别的样本数据行记录均衡。除此以外，还可以考虑使用或辅助于基于列的特征选择方法。一般情况下，样本不均衡也会导致特征分布不均衡，但如果小类别样本量具有一定的规模，那么意味着其特征值的分布较为均匀，可通过选择具有显著型的特征配合参与解决样本不均衡问题，也能在一定程度上提高模型效果。提示 上述几种方法的思路都是基于分类问题解决的。实际上，这种从大规模数据中寻找罕见数据的情况，也可以使用非监督式的学习方法，例如使用One-class SVM进行异常检测。分类是监督式方法，前期是基于带有标签（Label）的数据进行分类预测；而采用非监督式方法，则是使用除了标签以外的其他特征进行模型拟合，这样也能得到异常数据记录。所以，要解决异常检测类的问题，先是考虑整体思路，然后再考虑方法模型。</p>
</blockquote>
<p>其实这个东西是有很多文章用OCSVM做的，说是SVM其实是聚类，或者说SVDD更好，目前没有用这个，以后试试效果比较一下跟平衡权重哪个更好。</p>
<p>☺️☺️☺️☺️☺️☺️☺️☺️☺️☺️☺️☺️☺️</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/05/06/写写常见的几种最优化方法/"><span>梯度下降法和牛顿法</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/05/06/写写常见的几种最优化方法/" rel="bookmark">
        <time class="entry-date published" datetime="2017-05-06T08:35:00.000Z">
          2017-05-06
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="写写常见的几种最优化方法"><a href="#写写常见的几种最优化方法" class="headerlink" title="写写常见的几种最优化方法"></a>写写常见的几种最优化方法</h2><p>首先肯定是要说泰勒公式的了。。</p>
<p>泰勒公式是一个用函数在某点的信息描述其<em>附近</em>取值的公式。</p>
<p><strong>局部有效性</strong></p>
<p>它的基本形式是：<img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5hmziysij31kw089tan.jpg" alt=""></p>
<p>这是后续优化方法的迭代基础</p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>在机器学习任务中，需要最小化损失函数L（theta），其中theta是要求解的模型参数。梯度下降法常用来求解这种无约束最优化问题，它是一种迭代方法:选取初值，不断迭代，更新theta的值，进行损失函数的极小化。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。</p>
<p><img src="http://wx1.sinaimg.cn/mw690/006cxA6Hgy1fp5ht3pqwqj31kw0n8n2l.jpg" alt=""></p>
<p>这个图大概能表示梯度下降搜索迭代的概念</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Gradient_descent.png/350px-Gradient_descent.png" alt=""></p>
<p>同时还有共轭梯度下降，次梯度下降等。　共轭梯度法是介于最速下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。 在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。</p>
<p>还有两个概念：批量梯度下降法（Batch Gradient Descent，BGD），它得到的是一个全局最优解，但是每迭代一步，都要用到训练集所有的数据，如果m很大，那么可想而知这种方法的迭代速度会相当的慢。所以，这就引入了另外一种方法——随机梯度下降。随机梯度下降（Stochastic Gradient Descent，SGD）：随机梯度下降是通过每个样本来迭代更新一次，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将theta迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p>
<p>随机梯度下降每次迭代只使用一个样本，迭代一次计算量为n2，当样本个数m很大的时候，随机梯度下降迭代一次的速度要远高于批量梯度下降方法。两者的关系可以这样理解：随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量。</p>
<p>对批量梯度下降法和随机梯度下降法的总结：</p>
<p>   批量梯度下降—最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。</p>
<p>随机梯度下降—最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。</p>
<p>所以引入了mini-batch 梯度下降的概念，很棒了。</p>
<h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p>牛顿法和梯度下降法最直观的差别就是，前者进行了二阶的泰勒展开：</p>
<p><img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5hxpzbrbj31kw0xnwn8.jpg" alt=""><br>一个动图<br><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/NewtonIteration_Ani.gif" alt=""></p>
<p>从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</p>
<p>但是！牛顿法每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</p>
<p>所以就有了拟牛顿法</p>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p>拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p>
<p>这个又有很多内容了，DFP，BFGS啥的，在python里用起来很方便，但是最好还是要弄懂原理的，感觉心里会更清晰一点呢✌🏻</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/03/21/机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系/"><span>Bias(偏差)，Error(误差)，和Variance(方差)</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/03/21/机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系/" rel="bookmark">
        <time class="entry-date published" datetime="2017-03-21T02:31:23.000Z">
          2017-03-21
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="机器学习中的Bias-偏差-，Error-误差-，和Variance-方差-的区别和联系"><a href="#机器学习中的Bias-偏差-，Error-误差-，和Variance-方差-的区别和联系" class="headerlink" title="机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系"></a>机器学习中的Bias(偏差)，Error(误差)，和Variance(方差)的区别和联系</h2><p>这个比较基础的概念我觉得是很好理解的👌🏻</p>
<p>看图</p>
<p><img src="http://wx2.sinaimg.cn/mw690/006cxA6Hgy1fp5gbz8cmfj30k00tw0u5.jpg" alt=""></p>
<p>这个图基本上就能看懂他们的区别联系了：bias描述的是模型输出的<strong>预测结果的期望</strong>与真实结果的差距，如果要减小bias就需要增加模型复杂度，但是容易出现过拟合的情况，如右上图，会很分散（容易收到样本数据影响，稍微的扰动会带来很大影响）</p>
<p>variance和bias不同的是，它不是对样本拟合程度的反应，它表现的是模型在测试集上的表现，降低方差需要减小模型复杂度，但是会容易欠拟合，带来的结果是high bias。</p>
<p>一句话：</p>
<p>Bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异；<br>Variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。</p>
<p>所以bias和variance的选择是一个tradeoff。</p>
<p>噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p>Error = Bias^2 + Variance + Noise</p>
<p>不列出具体推导了，周志华老师的机器学习中写的很明白</p>
<h3 id="怎么避免过拟合和欠拟合"><a href="#怎么避免过拟合和欠拟合" class="headerlink" title="怎么避免过拟合和欠拟合"></a>怎么避免过拟合和欠拟合</h3><pre><code>避免欠拟合：

寻找更好的特征-----具有代表性的

用更多的特征-----增大输入向量的维度


避免过拟合：
增大数据集合-----使用更多的数据，噪声点比重减少

减少数据特征-----减小数据维度，高维空间密度小

正则化方法-----即在对模型的目标函数（objective function）或代价函数（cost function）加上正则项

交叉验证方法
</code></pre><h3 id="什么是交叉验证"><a href="#什么是交叉验证" class="headerlink" title="什么是交叉验证"></a>什么是交叉验证</h3><p>Cross-validation 是为了有效的估测 generalization error(泛化误差) 所设计的实验方法</p>
<p>将原始数据分成K组(一般是均分),将每个子集数据分别做一次验证集,其余的K-1组子集数据作为训练集,这样会得到K个模型,用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标.K一般大于等于2,实际操作时一般从3开始取,只有在原始数据集合数据量小的时候才会尝试取2. 而K-CV 的实验共需要建立 k 个models，并计算 k 次 test sets 的平均辨识率。在实作上，k 要够大才能使各回合中的 训练样本数够多，一般而言 k=10 (作为一个经验参数)算是相当足够了。</p>
<p>为什么要交叉验证呢：k-fold交叉验证常用来确定不同类型的模型（线性、指数等）哪一种更好，为了减少数据划分对模型评价的影响，最终选出来的模型类型（线性、指数等）是k次建模的误差平均值最小的模型。当k较大时，经过更多次数的平均可以学习得到更符合真实数据分布的模型，Bias就小了，但是这样一来模型就更加拟合训练数据集，再去测试集上预测的时候预测误差的期望值就变大了，从而Variance就大了；反之，k较小时模型不会过度拟合训练数据，从而Bias较大，但是正因为没有过度拟合训练数据，Variance也较小。</p>
<p>这个图是我看到比较清楚明了的了：</p>
<p><img src="http://wx4.sinaimg.cn/mw690/006cxA6Hgy1fp5h42bf9sj30jg0j8t9f.jpg" alt=""></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>



  <article>

  
    
    <h3 class="article-title"><a href="/2017/02/14/LDA知识点总结/"><span>线性判别分析是什么</span></a></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/02/14/LDA知识点总结/" rel="bookmark">
        <time class="entry-date published" datetime="2017-02-14T06:15:21.000Z">
          2017-02-14
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="LDA知识点总结"><a href="#LDA知识点总结" class="headerlink" title="LDA知识点总结"></a>LDA知识点总结</h2><blockquote>
<p>这个LDA不是NLP里的主题模型，是线性判别分析奥</p>
</blockquote>
<p>LDA的全称是Linear Discriminant Analysis（线性判别分析），是一种supervised learning。因为是由Fisher在1936年提出的，所以也叫Fisher’s Linear Discriminant。</p>
<p>一句话读懂LDA：<strong>投影后类内方差最小，类间方差最大</strong></p>
<p>LDA通常作为数据预处理阶段的降维技术，其目标是将数据投影到低维空间来避免维度灾难（curse of dimensionality）引起的过拟合，同时还保留着良好的可分性。也可以说它是一种分类算法，通过对历史数据进行投影，以保证投影后同一类别的数据尽量靠近，不同类别的数据尽量分开。并生成线性判别模型对新生成的数据进行分离和预测。所以我们能看到它是一种有效的特征抽取方法。使用这种方法能够使投影后模式样本的类间散布矩阵最大，并且同时类内散布矩阵最小。就是说，它能够保证投影后模式样本在新的空间中有最小的类内距离和最大的类间距离，即模式在该空间中有最佳的可分离性。</p>
<p>具体LDA分类基本思想：假设各个类别的样本数据符合高斯分布，这样利用LDA进行投影后，可以利用极大似然估计计算各个类别投影数据的均值和方差，进而得到该类别高斯分布的概率密度函数。当一个新的样本到来后，我们可以将它投影，然后将投影后的样本特征分别带入各个类别的高斯分布概率密度函数，计算它属于这个类别的概率，最大的概率对应的类别即为预测类别。</p>
<p>关于具体公式就不手打了，贴几张图形象的表示一下它的原理：</p>
<p><img src="http://wx1.sinaimg.cn/mw690/006cxA6Hgy1fp5f20x8vij31cy0es76e.jpg" alt=""></p>
<p>从直观上可以看出，右图要比左图的投影效果好，因为右图的黑色数据和蓝色数据各个较为集中，且类别之间的距离明显。左图则在边界处数据混杂。以上就是LDA的主要思想了，当然在实际应用中，我们的数据是多个类别的，我们的原始数据一般也是超过二维的，投影后的也一般不是直线，而是一个低维的超平面。</p>
<h3 id="PCA和LDA"><a href="#PCA和LDA" class="headerlink" title="PCA和LDA"></a>PCA和LDA</h3><p>PCA（主成分分析）和LDA（线性判别分析）有很多的相似点，其本质是要将初始样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</p>
<p>首先我们看看相同点：</p>
<p>1）两者均可以对数据进行降维。</p>
<p>2）两者在降维时均使用了矩阵特征分解的思想。</p>
<p>3）两者都假设数据符合高斯分布。</p>
<p>我们接着看看不同点：</p>
<p>1）LDA是有监督的降维方法，而PCA是无监督的降维方法</p>
<p>2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。</p>
<p>3）LDA除了可以用于降维，还可以用于分类。</p>
<p>4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。</p>
<h3 id="LDA优缺点分析"><a href="#LDA优缺点分析" class="headerlink" title="LDA优缺点分析"></a>LDA优缺点分析</h3><p>LDA算法的主要优点有：</p>
<p>1）在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。</p>
<p>2）LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。</p>
<p>LDA算法的主要缺点有：</p>
<p>1）LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。</p>
<p>2）LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。</p>
<p>3）LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。</p>
<p>4）LDA可能过度拟合数据。</p>
<p>scikit-learn中就能直接用LDA（sklearn.discriminant_analysis.LinearDiscriminantAnalysis）。一般来说，如果我们的数据是有类别标签的，那么优先选择LDA去尝试降维；当然也可以使用PCA做很小幅度的降维去消去噪声，然后再使用LDA降维。如果没有类别标签，那么肯定PCA是最先考虑的一个选择了。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>




<nav class="pagination">
  
  
  <a href="/page/2/" class="pagination-next">Next</a>
  
</nav>
    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2018 Yang He
    
  </p>
</footer>
    
  </div>
</div>
</body>
</html>